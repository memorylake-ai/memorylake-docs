---
title: "Quick Start"
description: "Complete your first model call using a unified entry point, covering OpenAI / Claude / Gemini examples and key points about quotas and logs"
---

## What You'll Get
- Reuse existing OpenAI / Claude / Gemini clients; you only need to change the Base URL and token to make calls.
- The platform validates quotas, pre-deducts, and directly rejects when insufficient, preventing overdrafts.
- Call logs record fields such as models, token names, channels, request latency, and tokens, facilitating troubleshooting and reconciliation.

## Use Cases
- Need to quickly verify token availability and quota settings.
- Want to switch to a unified entry point without modifying existing client code.
- Need to view request latency, tokens, and consumption to support subsequent reconciliation or troubleshooting.

## Quick Path: Get It Working
1) **Prepare**: Copy your token and note the platform API Base (example: `https://app.memorylake.ai`).  
2) **Choose a Model**: If unsure, first retrieve the model list: `GET /v1/models` (OpenAI-compatible endpoint).  
3) **Send a Minimal Call**: Follow the official format, only replace the Base URL and token:

<CodeGroup>
```bash OpenAI Compatible (chat/completions)
curl --request POST \
  --url https://app.memorylake.ai/v1/chat/completions \
  --header 'Authorization: Bearer sk-your-token' \
  --header 'Content-Type: application/json' \
  --data '{
    "model": "gpt-4o-mini",
    "messages": [{"role": "user", "content": "hi~"}]
  }'
```

```bash Claude Compatible (messages)
curl --request POST \
  --url https://app.memorylake.ai/claude/v1/messages \
  --header 'x-api-key: sk-your-token' \
  --header 'Content-Type: application/json' \
  --data '{
    "model": "claude-3-haiku-20240307",
    "max_tokens": 1024,
    "messages": [{"role": "user", "content": "hi~"}]
  }'
```

```bash Gemini Compatible (generateContent)
curl --request POST \
  --url https://app.memorylake.ai/gemini/v1alpha/models/gemini-2.0-pro-exp:generateContent \
  --header 'x-goog-api-key: sk-your-token' \
  --header 'Content-Type: application/json' \
  --data '{
    "contents": [{
      "role": "user",
      "parts": [{"text": "hi~"}]
    }]
  }'
```
</CodeGroup>

<Note>
Path conventions: OpenAI endpoint at `/v1`, Claude at `/claude/v1`, Gemini at `/gemini/:version`. All call examples use actual available platform paths.
</Note>

## Key Usage Points
- **Quota Rules**: Each call validates and pre-deducts quota; requests are rejected when quota is insufficient. Successful returns confirm deduction; failures roll back pre-deduction.
- **Model Selection**: Supports OpenAI / Claude / Gemini compatible formats. View currently available models via `GET /v1/models` or corresponding model list endpoints.
- **Channels and Proxies**: Channels can be configured with proxies or multipliers as needed. Final routing distributes based on model, channel configuration, and optional specified channel headers.
- **Special Features**: Supports capabilities like o1/o3 ReasoningEffort selection, Claude thinking, Gemini search and code execution, passed through via official parameters.

## What You'll See After a Successful Call
- **Log Records**: Fields such as model name, token name, channel, request latency (`request_time`), prompt and completion tokens are recorded for tracking and troubleshooting.
- **Aggregated Statistics**: Request counts, consumed quotas, tokens, and request latency are aggregated by date, facilitating dashboard display and quota reconciliation.

## Common Troubleshooting
- **Insufficient Quota**: Verify that token or account quota is sufficient; insufficient quota directly rejects requests.
- **No Available Route**: Confirm that the target model is enabled in the current route, or adjust model selection.
- **Specify Route**: When a fixed route is needed, specify via token suffix or specific header; if not specified, default automatic routing applies.

## You Might Also Want to Know
- Want to see more examples or special parameter usage: Check the [Protocols and Entry Points](/features/model-router/protocols-and-entrypoints) documentation.
- Want to verify billing: Reconcile using log fields and aggregated statistics; use a test token first to verify multipliers and model wildcards if needed.
