---
title: "Protocols and Entry Points"
description: "Choose the appropriate call entry point and protocol under the same platform to quickly complete model and task access"
---

## Feature Overview
You can access conversations, completions, multimodal tasks, and model directories through unified or native paths under the same platform without changing existing SDKs or calling habits.

## Use Cases and Prerequisites
- Need to use OpenAI-style `/v1` interfaces for chat, completion, responsive conversations, streaming conversations, images, voice, Embedding, content moderation, etc.
- Already using Claude or Gemini official SDKs and want to maintain native paths while only replacing the base address.
- Need to submit and query task-based capabilities like Midjourney, Suno, RecraftAI, Kling, etc.
- Prerequisites: Have obtained an available token in the console, and the corresponding group has enabled target models or task quotas.

## Entry Points and Protocols

### OpenAI-Compatible Entry Point (/v1 Series)
- Directly point SDK or HTTP client base addresses to `/v1` to complete chat, completion, responsive conversations, streaming conversations, reranking, image generation/editing/variants, Embedding, speech-to-text/translation/voice synthesis, content moderation, etc.
- In specified channel mode, supports passing through Files, Fine-tuning, Assistants, Threads, Batches, Vector Stores, keeping the original OpenAI ecosystem toolchain available.
- Request example (chat):

<CodeGroup>
```ts TypeScript
await fetch("https://app.memorylake.ai/v1/chat/completions", {
  method: "POST",
  headers: {
    "Authorization": "Bearer sk-demo123",
    "Content-Type": "application/json"
  },
  body: JSON.stringify({
    model: "gpt-4o-mini",
    messages: [{ role: "user", content: "Write a welcome message for a new product launch" }],
    stream: false
  })
});
```
```py Python
import requests

resp = requests.post(
    "https://app.memorylake.ai/v1/chat/completions",
    headers={
        "Authorization": "Bearer sk-demo123",
        "Content-Type": "application/json",
    },
    json={
        "model": "gpt-4o-mini",
        "messages": [{"role": "user", "content": "Write a welcome message for a new product launch"}],
        "stream": False,
    },
)
```
```bash cURL
curl https://app.memorylake.ai/v1/chat/completions \
  -H "Authorization: Bearer sk-demo123" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gpt-4o-mini",
    "messages": [{"role": "user", "content": "Write a welcome message for a new product launch"}],
    "stream": false
  }'
```
</CodeGroup>

- Streaming toggle: Set `stream` to `true` to return as an event stream.

### Native Path Entry Points (Claude / Gemini)
- Claude: Use the native message interface path `/claude/v1/messages`, only need to replace the base address.
- Gemini: Maintain official path format `/gemini/:version/models/:model`, choose version and model as needed.
- Continue using original SDK/HTTP structure without adjusting request body fields.
- Request example (Claude):

<CodeGroup>
```ts TypeScript
await fetch("https://app.memorylake.ai/claude/v1/messages", {
  method: "POST",
  headers: {
    "Authorization": "Bearer sk-demo123",
    "Content-Type": "application/json"
  },
  body: JSON.stringify({
    model: "claude-3-opus-20240229",
    max_tokens: 200,
    messages: [{ role: "user", content: "Summarize this week's highlights in one sentence" }]
  })
});
```
```py Python
import requests

resp = requests.post(
    "https://app.memorylake.ai/claude/v1/messages",
    headers={
        "Authorization": "Bearer sk-demo123",
        "Content-Type": "application/json",
    },
    json={
        "model": "claude-3-opus-20240229",
        "max_tokens": 200,
        "messages": [{"role": "user", "content": "Summarize this week's highlights in one sentence"}],
    },
)
```
```bash cURL
curl https://app.memorylake.ai/claude/v1/messages \
  -H "Authorization: Bearer sk-demo123" \
  -H "Content-Type: application/json" \
  -d '{
    "model": "claude-3-opus-20240229",
    "max_tokens": 200,
    "messages": [{"role": "user", "content": "Summarize this week's highlights in one sentence"}]
  }'
```
</CodeGroup>

- Request example (Gemini):

<CodeGroup>
```ts TypeScript
await fetch("https://app.memorylake.ai/gemini/v1beta/models/gemini-1.5-pro:generateContent", {
  method: "POST",
  headers: {
    "Authorization": "Bearer sk-demo123",
    "Content-Type": "application/json"
  },
  body: JSON.stringify({
    contents: [{ role: "user", parts: [{ text: "Generate a title" }] }]
  })
});
```
```py Python
import requests

resp = requests.post(
    "https://app.memorylake.ai/gemini/v1beta/models/gemini-1.5-pro:generateContent",
    headers={
        "Authorization": "Bearer sk-demo123",
        "Content-Type": "application/json",
    },
    json={
        "contents": [{"role": "user", "parts": [{"text": "Generate a title"}]}],
    },
)
```
```bash cURL
curl https://app.memorylake.ai/gemini/v1beta/models/gemini-1.5-pro:generateContent \
  -H "Authorization: Bearer sk-demo123" \
  -H "Content-Type: application/json" \
  -d '{
    "contents": [{"role": "user", "parts": [{"text": "Generate a title"}]}]
  }'
```
</CodeGroup>

### Task-Based Entry Points (Midjourney / Suno / RecraftAI / Kling)
- Midjourney: Supports task submission for imagine, describe, blend, change, shorten, notify, etc., and can query task progress and results, retrieve images, with support for face swap and image uploads.
- Suno: Submit music or voice-over tasks and query generation results.
- RecraftAI: Provides task-based interfaces for vectorization, background removal, generative and clarity enhancement, style management, etc.
- Kling: Supports task submission and result queries for text-to-video and image-to-video.
- Request example (Midjourney imagine):

<CodeGroup>
```ts TypeScript
await fetch("https://app.memorylake.ai/midjourney/imagine", {
  method: "POST",
  headers: {
    "Authorization": "Bearer sk-demo123",
    "Content-Type": "application/json"
  },
  body: JSON.stringify({
    prompt: "sunrise over a lake, cinematic",
    notify: true
  })
});
```
```py Python
import requests

resp = requests.post(
    "https://app.memorylake.ai/midjourney/imagine",
    headers={
        "Authorization": "Bearer sk-demo123",
        "Content-Type": "application/json",
    },
    json={
        "prompt": "sunrise over a lake, cinematic",
        "notify": True,
    },
)
```
```bash cURL
curl https://app.memorylake.ai/midjourney/imagine \
  -H "Authorization: Bearer sk-demo123" \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "sunrise over a lake, cinematic",
    "notify": true
  }'
```
</CodeGroup>

- Request example (Suno task):

<CodeGroup>
```ts TypeScript
await fetch("https://app.memorylake.ai/suno/jobs", {
  method: "POST",
  headers: {
    "Authorization": "Bearer sk-demo123",
    "Content-Type": "application/json"
  },
  body: JSON.stringify({
    prompt: "soft piano background music",
    mode: "music"
  })
});
```
```py Python
import requests

resp = requests.post(
    "https://app.memorylake.ai/suno/jobs",
    headers={
        "Authorization": "Bearer sk-demo123",
        "Content-Type": "application/json",
    },
    json={
        "prompt": "soft piano background music",
        "mode": "music",
    },
)
```
```bash cURL
curl https://app.memorylake.ai/suno/jobs \
  -H "Authorization: Bearer sk-demo123" \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "soft piano background music",
    "mode": "music"
  }'
```
</CodeGroup>

## Authentication and Available Models

### Obtaining and Using Tokens
- Generate tokens in the console and use them as credentials for calls; available models and quotas for different tokens or token groups do not interfere with each other.

### Viewing Available Model Directory
- Get models and source information available to the current token through `/v1/models`, `/claude/v1/models`, `/gemini/*/models`, then confirm the callable range before making requests.
- Example placeholder: Please replace with actual model list response screenshot here.

## Request Essentials and Responses

### Common Request Patterns
- OpenAI-compatible entry points follow corresponding interface fields and response formats, can directly use existing examples or SDKs.
- Native path entry points maintain their respective protocol fields to avoid adaptation costs due to field differences.

### Streaming and Non-Streaming
- Supports streaming and non-streaming responses: use according to the target interface's streaming toggle or event stream format; streaming scenarios provide heartbeat and exception fallback to reduce interruption risks.

### Task Submission and Query
- Task interfaces require submitting tasks first, then using query interfaces to get status and results; submission and query must use the same token environment to ensure task visibility.
- Query example (task status):

<CodeGroup>
```ts TypeScript
await fetch("https://app.memorylake.ai/tasks/tsk_12345", {
  headers: { "Authorization": "Bearer sk-demo123" }
});
```
```py Python
import requests

resp = requests.get(
    "https://app.memorylake.ai/tasks/tsk_12345",
    headers={"Authorization": "Bearer sk-demo123"}
)
```
```bash cURL
curl https://app.memorylake.ai/tasks/tsk_12345 \
  -H "Authorization: Bearer sk-demo123"
```
</CodeGroup>

## Usage Recommendations
- Before making requests, call the model directory interface to confirm available models and channels to avoid targets being unavailable.
- If you already have OpenAI-style SDKs, prefer the `/v1` entry point; when using Claude or Gemini official SDKs, maintain original paths and only replace the base address.
- For long streaming or batch tasks, pay attention to notification alerts and stagger appropriately to reduce rate limiting impact.

## Known Limitations and Boundaries
- Available models, task capabilities, and quotas are based on actual console and token group configuration; unenabled models or tasks are unavailable.
- Pricing and owned_by metadata are based on model directory returns; actual billing is based on settlement results.
- Notifications and content moderation need to be enabled in the console or configuration with correct channel information; they do not take effect if not enabled.
- Task submission and query depend on corresponding channels being enabled and require using the same token environment to complete the full chain.
